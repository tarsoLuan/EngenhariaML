{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68084f4f-1a6b-41d2-9b9f-e5a4b1f599e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from sklearn import linear_model, preprocessing, metrics, model_selection\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "if 'inline_rc' not in dir():\n",
    "    inline_rc = dict(mpl.rcParams)\n",
    "\n",
    "SEED = 10\n",
    "\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.WARN)\n",
    "# logger = logging.getLogger(__name__)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7cfc943-790e-46af-bb10-1ffff849122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset matplotlib\n",
    "\n",
    "mpl.rcParams.update(inline_rc)\n",
    "font = {'size'   : 14}\n",
    "mpl.rc('font', **font)\n",
    "lines = {'linewidth' : 3}\n",
    "mpl.rc('lines', **lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4b6961f-a3d2-40b1-b59c-4346fba5a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model_name = 'modelo_kobe'\n",
    "min_precision = 0.7\n",
    "model_version = -1 # recuperar a ultima versao\n",
    "nexamples = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed8b313e-8396-4313-b518-c67dc3ad2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para usar o sqlite como repositorio\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "experiment_name = 'First Training Kobe Model'\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "experiment_id = experiment.experiment_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a08c9b-1dbc-4496-bc64-2434a7712faf",
   "metadata": {},
   "source": [
    "# Leitura dos Dados de Classificação de shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e58e6f7-f8bb-498a-81f4-dc8175053cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat                  0\n",
       "lon                  0\n",
       "minutes_remaining    0\n",
       "period               0\n",
       "playoffs             0\n",
       "shot_distance        0\n",
       "shot_made_flag       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COLOCAR RUN DE LEITURA DE DADOS\n",
    "# PARAMETROS: top_features,\n",
    "# METRICS: SHAPE de cada base de dados\n",
    "# ARTIFACTS: nenhum\n",
    "\n",
    "top_features = ['lat','lon','minutes_remaining', 'period', 'playoffs','shot_distance']\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'PreparacaoDados'):\n",
    "    dataset_dev = pd.read_csv('../Data/Raw/dataset_kobe.csv',sep=',')\n",
    "    kobe_target_col = 'shot_made_flag'\n",
    "\n",
    "    dataset_dev = dataset_dev.dropna()\n",
    "    \n",
    "\n",
    "    dataset_dev = dataset_dev[top_features + [kobe_target_col]].copy()\n",
    "    # Separar parte para compor a base de operacao\n",
    "    dataset_dev, dataset_prod, ytrain, ytest = model_selection.train_test_split(dataset_dev, \n",
    "                                                                            dataset_dev[kobe_target_col],\n",
    "                                                                            test_size=0.2)\n",
    "    dataset_dev[kobe_target_col]      = ytrain\n",
    "    dataset_prod[kobe_target_col] = ytest\n",
    "\n",
    "    # SALVAR BASES DE DADOS\n",
    "    dataset_dev.to_parquet('../Data/Processed/base_train.parquet')\n",
    "    dataset_prod.to_parquet('../Data/Processed/base_test.parquet')\n",
    "\n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"top_features\", top_features)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"data_dev\", dataset_dev.shape[0])\n",
    "    mlflow.log_metric(\"data_operation\", dataset_prod.shape[0]) \n",
    "    \n",
    "mlflow.end_run()\n",
    "\n",
    "dataset_dev.head()\n",
    "dataset_dev.isna().sum()\n",
    "\n",
    "# print('== Bases de Dados ==')\n",
    "# print(f'data_wine {dataset_dev.shape}')\n",
    "# print(f'data_operation {dataset_prod.shape}')\n",
    "# print(f'Columns: {dataset_dev.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22dd5e42-518a-4407-8c17-50f8e52ca0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlflow ui --backend-store-uri sqlite:///mlruns.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80922f9-7c07-463e-b97f-75f4ac3c2303",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1ee4b-e4bd-4ae8-b759-bdf99155ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret.classification as pc\n",
    "# COLOCAR RUN DE TREINAMENTO DE MODELOS\n",
    "# PARAMETROS: fold_strategy, fold, model_name, registered_model_name, cross_validation\n",
    "# METRICS: auto sklearn\n",
    "# ARTIFACTS: plots\n",
    "\n",
    "model_name = 'lr'\n",
    "probability_threshold = 0.5\n",
    "cross_validation = True\n",
    "fold_strategy = 'stratifiedkfold',\n",
    "fold = 10\n",
    "\n",
    "# train/test\n",
    "s = pc.setup(data = dataset_dev, \n",
    "             target = kobe_target_col,\n",
    "             train_size=0.7,\n",
    "             fold_strategy = 'stratifiedkfold',\n",
    "             fold = fold,\n",
    "             log_experiment = True, \n",
    "             experiment_name = experiment_name, \n",
    "             log_plots = True\n",
    "            )\n",
    "bestmodel = pc.create_model(model_name,\n",
    "                            cross_validation = cross_validation, \n",
    "                            probability_threshold=probability_threshold)\n",
    "\n",
    "# Log do run, e nao do modelo respectivo\n",
    "classification_plots = [ 'auc','pr','confusion_matrix',\n",
    "#                          'error', 'class_report', \n",
    "                        'threshold',\n",
    "                         'learning',\n",
    "                        # 'vc',\n",
    "                        # 'feature',\n",
    "                       ]\n",
    "for plot_type in classification_plots:\n",
    "    print('=> Aplicando plot ', plot_type)\n",
    "    try:\n",
    "        artifact = pc.plot_model(bestmodel, plot=plot_type, save=True)\n",
    "        mlflow.log_artifact(artifact)\n",
    "    except:\n",
    "        print('=> Nao possivel plotar: ', plot_type )\n",
    "        continue\n",
    "\n",
    "pc.save_model(bestmodel, f'./{registered_model_name}') \n",
    "# Carrega novamente o pipeline + bestmodel\n",
    "model_pipe = pc.load_model(f'./{registered_model_name}')\n",
    "\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098336eb-7295-4ae5-bd7a-b827cab194c4",
   "metadata": {},
   "source": [
    "# Avaliar Precisão Mínima "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b998b9-1442-4f28-9e0e-e0ad30043a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCAR RUN APROVACAO DE MODELO\n",
    "# PARAMETROS: min_precision\n",
    "# METRICS: new_version, precision\n",
    "# ARTIFACTS: None\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'AprovacaoModelo'):\n",
    "    pred_holdout = pc.predict_model(bestmodel, raw_score=True)\n",
    "    pred_holdout.drop('prediction_score_0', axis=1, inplace=True)\n",
    "    pred_holdout.rename({'prediction_score_1': 'prediction_score'}, axis=1, inplace=True)\n",
    "    pr = metrics.precision_score(pred_holdout[kobe_target_col], pred_holdout['prediction_label'])\n",
    "    if pr > min_precision:\n",
    "        print(f'=> Aceito o modelo com precisão {pr} (min: {min_precision})')\n",
    "        pred_holdout.to_parquet('../Data/Processed/modelo_kobe_teste.parquet')\n",
    "        # Assinatura do Modelo Inferida pelo MLFlow\n",
    "        model_features = list(data_wine.drop(wine_target_col, axis=1).columns)\n",
    "        inf_signature = infer_signature(data_wine[model_features], \n",
    "                                        model_pipe.predict(data_wine.drop(wine_target_col, axis=1)))\n",
    "        # Exemplo de entrada para o MLmodel\n",
    "        input_example = {x: data_wine[x].values[:nexamples] for x in model_features}\n",
    "        # Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model_pipe,\n",
    "            artifact_path=\"sklearn-model\",\n",
    "            registered_model_name=registered_model_name,\n",
    "            signature = inf_signature,\n",
    "            input_example = input_example\n",
    "        )\n",
    "        # Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "        client = MlflowClient()\n",
    "        model_version = client.get_latest_versions(registered_model_name)[-1].version\n",
    "        # Registrar o modelo como staging\n",
    "        client.set_registered_model_alias(\n",
    "            name    = registered_model_name, \n",
    "            alias   = \"staging\", \n",
    "            version = model_version\n",
    "        )\n",
    "    else:\n",
    "        print(f'=> Rejeitado o modelo com precisão {pr} (min: {min_precision})')\n",
    "\n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"precisao_minima\", min_precision)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"new_version\", model_version)\n",
    "    mlflow.log_metric(\"precisao\", pr)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb2933-4d3e-40a8-ac09-43ab51ada57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
